{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbCount : 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from datetime import datetime, timezone \n",
    "from Classes import Document, Author, HackerNewsDocument, TheGuardianDocument\n",
    "from bs4 import BeautifulSoup\n",
    "from Corpus import Corpus, DocumentFactory\n",
    "from scipy.sparse import csr_matrix\n",
    "from SearchEngine import SearchEngine\n",
    "\n",
    "#--------------D√©finition des variables\n",
    "#variable pour stocker les documents √† l'√©tat 'brut'\n",
    "collection = []\n",
    "#Nombre d'articles √† r√©cup√©rer\n",
    "nbDoc = 10\n",
    "#query = [\"Day\",\"Country\",\"Travel\",\"Tokyo\"] \n",
    "query =\"War\"\n",
    "api_key_guardian = \"265a16e3-294c-4c62-ae88-a274906a6333\"\n",
    "\n",
    "\n",
    "def search_query(texte,mots_cles) : \n",
    "    #V√©rifie si un des mots cl√©s est pr√©sent dans le texte ou le titre\n",
    "    return any(mot.lower() in texte.lower() for mot in mots_cles)\n",
    "\n",
    "def extraire_text_url(url) : \n",
    "    try:\n",
    "        #On r√©cup√®re la page html puis on v√©rifie si la requ√™te a r√©ussi\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        #On extrait uniquement les balises <p> pr√©sentes dans le body\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        body = soup.body\n",
    "        if body is None:\n",
    "            return \"Texte non disponible\" #Car pas de body\n",
    "           \n",
    "        paragraphes = body.find_all(\"p\")    #Texte √† partir du body\n",
    "        texte = \"\\n\".join(p.get_text(strip=True) for p in paragraphes)\n",
    "        if(texte.strip) : \n",
    "            return texte\n",
    "        else : \n",
    "            return \"Texte non disponible\"\n",
    "    except Exception :\n",
    "        return \"Texte non disponible\"\n",
    "\n",
    "#-----------------------WebScrapping avec Hacker News API\n",
    "def add_doc_HackerNews(collection,query,nbDoc) :\n",
    "    #Nombre de storys r√©cup√©r√©es\n",
    "    nbCount =0\n",
    "    url = \"https://hacker-news.firebaseio.com/v0/beststories.json\"\n",
    "    response = requests.get(url)\n",
    "    #Renvoie une exception si aucun article n'a √©t√© trouv√© \n",
    "    if response.status_code !=200 : \n",
    "        raise Exception(f\"Aucun texte provenant de HackerNews ne correspond √† la recherche {query}\")\n",
    "    \n",
    "    top_stories = response.json()\n",
    "    for id in top_stories[:1000]:  #C'est pour √™tre s√ªr d'avoir un jeu de donn√©es cons√©quent\n",
    "        #Si on a atteint le nombre de doc, on arr√™te de chercher\n",
    "        if nbCount >= nbDoc:\n",
    "            break\n",
    "\n",
    "        url = f\"https://hacker-news.firebaseio.com/v0/item/{id}.json\"\n",
    "        \n",
    "        data = requests.get(url)\n",
    "        data = data.json()\n",
    "        #R√©cup√©ration des donn√©es pour chaque url\n",
    "        titre = data.get(\"title\", \"No title\")\n",
    "        auteur = data.get(\"by\", \"Unknown\")\n",
    "        timestamp = data.get(\"time\", 0)\n",
    "        #Formatage de la date \n",
    "        date = datetime.fromtimestamp(timestamp, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        article_url = data.get(\"url\")\n",
    "        texte = extraire_text_url(article_url)  \n",
    "        score = data.get(\"score\", 0)\n",
    "\n",
    "        #On cr√©√© un document √† partir des informations r√©colt√©es\n",
    "        if texte != \"Texte non disponible\" :\n",
    "            #On applique la recherche de mots cl√©s sur le titre et le texte\n",
    "            if search_query(titre, query) or search_query(texte, query):\n",
    "                doc = DocumentFactory.creerDoc('HackerNews', titre, auteur, date, article_url, texte, score)\n",
    "                collection.append(doc)\n",
    "                nbCount +=1\n",
    "    return collection\n",
    "\n",
    "#-----------------------WebScrapping avec The Guardian API\n",
    "def add_doc_Guardian(collection, query, nbDoc, api_key):\n",
    "    nbCount = 0\n",
    "    url = f\"https://content.guardianapis.com/search?q={query}&page-size={nbDoc}&api-key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    #Renvoie une exception si aucun article n'a √©t√© trouv√© \n",
    "    if response.status_code !=200 : \n",
    "        raise Exception(f\"Aucun article provenant de The Guardian ne correspond √† la recherche {query}\")\n",
    "    \n",
    "    data = response.json()\n",
    "    for article in data[\"response\"][\"results\"]:\n",
    "        #Si on a atteint le nombre de doc, on arr√™te de chercher\n",
    "        if nbCount >= nbDoc:\n",
    "            break\n",
    "        #R√©cup√©ration des donn√©es pour chaque url\n",
    "        titre = article[\"webTitle\"]\n",
    "        article_url = article[\"webUrl\"]\n",
    "        texte = extraire_text_url(article_url)\n",
    "        try :   #Il n'y a pas tout le temps des auteurs\n",
    "            auteur = article.get(\"author\", \"Auteur inconnu\")\n",
    "        except : \n",
    "            auteur = \"The Guardian\"\n",
    "        # Premi√®re date de publication (on r√©cup√®re sous forme de string avant de la convertir en date)\n",
    "        release_date_str = article.get(\"firstPublicationDate\", \"\")\n",
    "        release_date = None     #Il faut instancier\n",
    "        if release_date_str:\n",
    "            release_date = datetime.strptime(release_date_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")  \n",
    "        \n",
    "        # Derni√®re date de mise √† jour (on r√©cup√®re sous forme de string avant de la convertir en date)\n",
    "        last_maj_str = article.get(\"lastModified\", \"\")\n",
    "        last_maj = None         #Il faut instancier\n",
    "        if last_maj_str:\n",
    "            last_maj = datetime.strptime(last_maj_str, \"%Y-%m-%dT%H:%M:%S.%fZ\") \n",
    "\n",
    "        if texte != \"Texte non disponible\":\n",
    "            doc = DocumentFactory.creerDoc('The_Guardian', titre, auteur, last_maj, article_url, texte, release_date)\n",
    "            collection.append(doc)\n",
    "            nbCount += 1\n",
    "\n",
    "    return collection\n",
    "\n",
    "#-------------------RECUPERATION DES DONNEES\n",
    "add_doc_HackerNews(collection,query,nbDoc) \n",
    "add_doc_Guardian(collection,query, nbDoc, api_key_guardian)\n",
    "'''\n",
    "for doc in collection : \n",
    "    print(doc.texte)\n",
    "    print('------------------------------')\n",
    "'''\n",
    "print(f\"nbCount : {len(collection)}\")    \n",
    "\n",
    "\n",
    "# Cr√©ation de l'index de documents √† partir de la collection\n",
    "#Cl√© : un Id \n",
    "#Valeur : le titre du document\n",
    "id2doc = {}\n",
    "for i, doc in enumerate(collection):\n",
    "    id2doc[i] = doc.titre\n",
    "\n",
    "authors = {}\n",
    "aut2id = {}\n",
    "num_auteurs_vus = 0\n",
    "\n",
    "# Cr√©ation de l'index des Auteurs √† partir de la collection\n",
    "#Cl√© : un Id (en fonction de la valeur de la variable num_auteurs_vus)\n",
    "#Valeur : un objet de type Author\n",
    "for doc in collection:\n",
    "    if doc.auteur not in aut2id:\n",
    "        num_auteurs_vus += 1\n",
    "        authors[num_auteurs_vus] = Author(doc.auteur)\n",
    "        aut2id[doc.auteur] = num_auteurs_vus\n",
    "    authors[aut2id[doc.auteur]].add(doc.texte)\n",
    "\n",
    "\n",
    "# Construction du corpus √† partir des documents pr√©sents dans la collection\n",
    "corpus = Corpus(\"Mon corpus\")\n",
    "for doc in collection:\n",
    "    corpus.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3567 mots diff√©rents dans le vocabulaire\n",
      "Les 10 mots les plus fr√©quents :\n",
      "            Mot   TF  DF\n",
      "1727       said  104   9\n",
      "429     quantum   46   1\n",
      "644          us   46  10\n",
      "1617    russian   42   7\n",
      "1096      genie   41   1\n",
      "1585  zelenskyy   39   6\n",
      "1553  ukrainian   35   7\n",
      "1614        war   35   9\n",
      "398       would   33   9\n",
      "409         new   33   8\n"
     ]
    }
   ],
   "source": [
    "from SearchEngine import SearchEngine\n",
    "search_engine = SearchEngine(corpus)\n",
    "results = search_engine.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865ec91a500b4252b97c11417c4896ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='color: lightpink; text-align: center;'>üïµüèΩ\\u200d‚ôÄÔ∏è Mon moteur de recherch‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3567 mots diff√©rents dans le vocabulaire\n",
      "Les 10 mots les plus fr√©quents :\n",
      "            Mot   TF  DF\n",
      "1727       said  104   9\n",
      "429     quantum   46   1\n",
      "644          us   46  10\n",
      "1617    russian   42   7\n",
      "1096      genie   41   1\n",
      "1585  zelenskyy   39   6\n",
      "1553  ukrainian   35   7\n",
      "1614        war   35   9\n",
      "398       would   33   9\n",
      "409         new   33   8\n",
      "3567 mots diff√©rents dans le vocabulaire\n",
      "Les 10 mots les plus fr√©quents :\n",
      "            Mot   TF  DF\n",
      "1727       said  104   9\n",
      "429     quantum   46   1\n",
      "644          us   46  10\n",
      "1617    russian   42   7\n",
      "1096      genie   41   1\n",
      "1585  zelenskyy   39   6\n",
      "1553  ukrainian   35   7\n",
      "1614        war   35   9\n",
      "398       would   33   9\n",
      "409         new   33   8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3567 mots diff√©rents dans le vocabulaire\n",
      "Les 10 mots les plus fr√©quents :\n",
      "            Mot   TF  DF\n",
      "1727       said  104   9\n",
      "429     quantum   46   1\n",
      "644          us   46  10\n",
      "1617    russian   42   7\n",
      "1096      genie   41   1\n",
      "1585  zelenskyy   39   6\n",
      "1553  ukrainian   35   7\n",
      "1614        war   35   9\n",
      "398       would   33   9\n",
      "409         new   33   8\n",
      "3567 mots diff√©rents dans le vocabulaire\n",
      "Les 10 mots les plus fr√©quents :\n",
      "            Mot   TF  DF\n",
      "1727       said  104   9\n",
      "429     quantum   46   1\n",
      "644          us   46  10\n",
      "1617    russian   42   7\n",
      "1096      genie   41   1\n",
      "1585  zelenskyy   39   6\n",
      "1553  ukrainian   35   7\n",
      "1614        war   35   9\n",
      "398       would   33   9\n",
      "409         new   33   8\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as wg\n",
    "from IPython.display import display, HTML\n",
    "from SearchEngine import SearchEngine\n",
    "import pandas as pd\n",
    "\n",
    "label = wg.HTML(\n",
    "    \"<h2 style='color: lightpink; text-align: center;'>üïµüèΩ‚Äç‚ôÄÔ∏è Mon moteur de recherche üîé</h2>\"\n",
    ")\n",
    "\n",
    "text_widget = wg.Text(\n",
    "    placeholder=\"Entrez vos mots ici\",\n",
    "    layout=wg.Layout(width='300px')\n",
    ")\n",
    "\n",
    "text_input = wg.HBox([\n",
    "    wg.HTML(\n",
    "        \"<b style='font-size: 16px; color: lightgreen;'>Mots cl√©s :</b>\"\n",
    "    ),\n",
    "    text_widget\n",
    "])\n",
    "\n",
    "slider = wg.HBox([\n",
    "    wg.HTML(\n",
    "        \"<b style='font-size: 12px; color: grey;'>Nb de documents :</b>\"\n",
    "    ),\n",
    "    wg.IntSlider(\n",
    "        value=5, \n",
    "        min=1, \n",
    "        max=20, \n",
    "        step=1,\n",
    "        layout=wg.Layout(width='150px')  \n",
    "    ),\n",
    "    wg.HTML(\n",
    "        \"<b style='font-size: 12px; color: grey; margin-left: 20px;'>Type :</b>\"\n",
    "    ),\n",
    "    wg.Dropdown(\n",
    "        options=[\"Tout\"] + [\"The_Guardian\", \"HackerNews\"],  \n",
    "        value=\"Tout\",\n",
    "        layout=wg.Layout(width='120px')\n",
    "    )\n",
    "])\n",
    "\n",
    "search_button = wg.Button(\n",
    "    description=\"Rechercher\", \n",
    "    icon=\"search\",\n",
    "    style={'button_color': '#FFDAB9'}\n",
    ")\n",
    "\n",
    "output = wg.Output()\n",
    "\n",
    "def search_corpus(corpus, query, max_docs, filtre_type):\n",
    "    search_engine = SearchEngine(corpus)\n",
    "\n",
    "    with output:\n",
    "        output.clear_output() # effacer la sortie pr√©c√©dente\n",
    "\n",
    "        try:\n",
    "            result_generator = search_engine.search(query)\n",
    "            # s'il n'y a pas de r√©sultats \n",
    "            if result_generator.empty:\n",
    "                print(f\"Aucun r√©sultat trouv√© pour la requ√™te : '{query}'\")\n",
    "                return\n",
    "            \n",
    "            # on v√©rifie si l'utilisateur a utilis√© un filte\n",
    "            if filtre_type != 'Tout' : \n",
    "                result_generator = result_generator[result_generator[\"Type\"] == filtre_type]\n",
    "\n",
    "            # on construit le code html \n",
    "            results_html = \"<br>\"\n",
    "            for i, excerpt in result_generator.iterrows():\n",
    "                if i >= max_docs:  # limiter le nombre de r√©sultats\n",
    "                    break\n",
    "                # hypertextualiser (?) le lien pour acc√®der au document sur sa page web\n",
    "                url = excerpt['URL'] if excerpt['URL'] != 'Non disponible' else None \n",
    "                type_doc = excerpt['Type']\n",
    "                hyperlien = f\"<a href='{url}' target='_blank' style='color: darkred;'>Acc√®s au document sur {type_doc}</a>\" if url else \"Non disponible\"\n",
    "                results_html += (\n",
    "                    f\"<div style='margin-bottom: 20px;'>\"\n",
    "                    f\"<b style='color: darkblue;'>{excerpt['Titre']} </b><br>\"\n",
    "                    f\"<b style='color: darkgreen;'>Extrait :</b> <b>{excerpt['Extrait']}</b><br>\"\n",
    "                    f\"{hyperlien}<br>\"\n",
    "                    f\"</div>\"\n",
    "                )\n",
    "            # on affiche les r√©sultats sur l'interface\n",
    "            display(HTML(results_html))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Erreur lors de la recherche :\", str(e))\n",
    "            return\n",
    "\n",
    "def clique_bouton(b) :\n",
    "    query = text_widget.value\n",
    "    num_docs = slider.children[1].value\n",
    "    type_choisi = slider.children[3].value\n",
    "    with output :\n",
    "        output.clear_output()\n",
    "        if not query.strip() :\n",
    "            return\n",
    "    search_corpus(corpus, query, num_docs, type_choisi)\n",
    "\n",
    "search_button.on_click(clique_bouton)\n",
    "\n",
    "interface = wg.VBox([label, text_input, slider, search_button, output],\n",
    "        layout=wg.Layout(justify_content=\"center\", \n",
    "        align_items=\"center\",         \n",
    "        padding=\"20px\"))\n",
    "display(interface)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
